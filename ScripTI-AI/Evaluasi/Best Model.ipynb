{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457ae86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python3.11.9\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membaca data uji: D:\\71210730\\Versi 4\\Training SBERT\\test_sbert.csv\n",
      "Jumlah Data Uji: 6000\n",
      "\n",
      "Sedang menguji: Indo-E5 Small...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:07<00:00, 12.91it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:06<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Selesai. Spearman: 0.8894\n",
      "\n",
      "Sedang menguji: SimCSE IndoBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:24<00:00,  3.76it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:21<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Selesai. Spearman: 0.8958\n",
      "\n",
      "Sedang menguji: NusaBERT Base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:27<00:00,  3.41it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:24<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Selesai. Spearman: 0.8983\n",
      "\n",
      "Sedang menguji: NusaBERT Large...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:17<00:00,  1.22it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:10<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Selesai. Spearman: 0.8796\n",
      "\n",
      "========================================\n",
      "ðŸ† HASIL AKHIR EVALUASI (LEADERBOARD) ðŸ†\n",
      "========================================\n",
      "        Nama Model  Spearman Correlation\n",
      "0    NusaBERT Base              0.898317\n",
      "1  SimCSE IndoBERT              0.895776\n",
      "2    Indo-E5 Small              0.889431\n",
      "3   NusaBERT Large              0.879556\n",
      "\n",
      "File tersimpan: hasil_evaluasi_model.csv\n",
      "\n",
      "ðŸ¥‡ Juara 1: NusaBERT Base\n",
      "Gunakan model ini untuk sistem Backend ScripTi kamu!\n"
     ]
    }
   ],
   "source": [
    "# ================= CELL EVALUASI: MODEL LEADERBOARD =================\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- 1. KONFIGURASI PATH ---\n",
    "# Masukkan path folder tempat kamu menyimpan HASIL TRAINING (bukan model mentah)\n",
    "TRAINED_MODELS = {\n",
    "    \"Indo-E5 Small\": r\"D:\\71210730\\Eval\\\\\\Trained_SBERT\\\\finetuned_indo_e5_v1\",\n",
    "    \"SimCSE IndoBERT\": r\"D:\\71210730\\Eval\\\\\\Trained_SBERT\\\\finetuned_simcse-indobert-base_v1\", \n",
    "    \"NusaBERT Base\": r\"D:\\71210730\\Eval\\\\\\Trained_SBERT\\\\finetuned_all-nusabert-base_v1\",\n",
    "    \"NusaBERT Large\": r\"D:\\71210730\\Eval\\\\\\Trained_SBERT\\\\finetuned_nusabert_large_v1\"\n",
    "}\n",
    "\n",
    "TEST_DATA_PATH = \"D:\\\\71210730\\\\Versi 4\\\\Training SBERT\\\\test_sbert.csv\"\n",
    "\n",
    "# --- 2. LOAD TEST DATA ---\n",
    "print(f\"Membaca data uji: {TEST_DATA_PATH}\")\n",
    "df_test = pd.read_csv(TEST_DATA_PATH, encoding='utf-8-sig')\n",
    "print(f\"Jumlah Data Uji: {len(df_test)}\")\n",
    "\n",
    "# Ambil list kalimat dan skor label\n",
    "sentences1 = df_test['text_1'].tolist()\n",
    "sentences2 = df_test['text_2'].tolist()\n",
    "gold_scores = df_test['score_norm'].tolist()\n",
    "\n",
    "# --- 3. FUNGSI EVALUASI ---\n",
    "def evaluate_model(model_path, model_name):\n",
    "    print(f\"\\nSedang menguji: {model_name}...\")\n",
    "    \n",
    "    # Cek apakah folder ada\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ Path tidak ditemukan: {model_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Load Model\n",
    "        model = SentenceTransformer(model_path)\n",
    "        \n",
    "        # Cek apakah butuh prefix (khusus E5)\n",
    "        # Kita pakai logika sederhana: kalau namanya mengandung 'e5', tambah query\n",
    "        prefix = \"query: \" if \"e5\" in model_name.lower() else \"\"\n",
    "        \n",
    "        # Encode (Batching biar aman memori)\n",
    "        # Tambahkan prefix jika perlu\n",
    "        input_s1 = [prefix + str(s) for s in sentences1]\n",
    "        input_s2 = [prefix + str(s) for s in sentences2]\n",
    "        \n",
    "        emb1 = model.encode(input_s1, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "        emb2 = model.encode(input_s2, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "        \n",
    "        # Hitung Cosine Similarity\n",
    "        cosine_scores = util.cos_sim(emb1, emb2).diagonal().cpu().numpy()\n",
    "        \n",
    "        # Hitung Spearman Correlation\n",
    "        corr, _ = spearmanr(gold_scores, cosine_scores)\n",
    "        print(f\"âœ… Selesai. Spearman: {corr:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            \"Nama Model\": model_name,\n",
    "            \"Spearman Correlation\": corr,\n",
    "            \"Path\": model_path\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error pada {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 4. EKSEKUSI LOOP ---\n",
    "results = []\n",
    "\n",
    "for name, path in TRAINED_MODELS.items():\n",
    "    res = evaluate_model(path, name)\n",
    "    if res:\n",
    "        results.append(res)\n",
    "\n",
    "# --- 5. TAMPILKAN LEADERBOARD ---\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ðŸ† HASIL AKHIR EVALUASI (LEADERBOARD) ðŸ†\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "if results:\n",
    "    df_results = pd.DataFrame(results)\n",
    "    # Urutkan dari skor tertinggi\n",
    "    df_results = df_results.sort_values(by=\"Spearman Correlation\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(df_results[[\"Nama Model\", \"Spearman Correlation\"]])\n",
    "    \n",
    "    # Simpan ke CSV untuk laporan skripsi\n",
    "    df_results.to_csv(\"hasil_evaluasi_model.csv\", index=False)\n",
    "    print(\"\\nFile tersimpan: hasil_evaluasi_model.csv\")\n",
    "    \n",
    "    best_model_name = df_results.iloc[0]['Nama Model']\n",
    "    print(f\"\\nðŸ¥‡ Juara 1: {best_model_name}\")\n",
    "    print(\"Gunakan model ini untuk sistem Backend ScripTi kamu!\")\n",
    "else:\n",
    "    print(\"Tidak ada hasil evaluasi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1cca6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python3.11.9\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai Evaluasi Komprehensif...\n",
      "\n",
      "ðŸ”¹ Menguji: Indo-E5 Small...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:06<00:00, 14.00it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:06<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >> Spearman: 0.8894\n",
      "   >> Pearson : 0.9110\n",
      "\n",
      "ðŸ”¹ Menguji: SimCSE IndoBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:27<00:00,  3.41it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:24<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >> Spearman: 0.8958\n",
      "   >> Pearson : 0.9133\n",
      "\n",
      "ðŸ”¹ Menguji: NusaBERT Base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:30<00:00,  3.04it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:28<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >> Spearman: 0.8983\n",
      "   >> Pearson : 0.9172\n",
      "\n",
      "ðŸ”¹ Menguji: NusaBERT Large...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:23<00:00,  1.12it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:15<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >> Spearman: 0.8796\n",
      "   >> Pearson : 0.8996\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š TABEL PERBANDINGAN PERFORMA MODEL\n",
      "==================================================\n",
      "             Model  Spearman   Pearson\n",
      "0    NusaBERT Base  0.898317  0.917196\n",
      "1  SimCSE IndoBERT  0.895776  0.913335\n",
      "2    Indo-E5 Small  0.889431  0.910976\n",
      "3   NusaBERT Large  0.879556  0.899570\n"
     ]
    }
   ],
   "source": [
    "# ================= CELL EVALUASI LENGKAP (SPEARMAN + PEARSON) =================\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "# Gunakan path yang sama seperti tadi\n",
    "TRAINED_MODELS = {\n",
    "    \"Indo-E5 Small\": r\"D:\\71210730\\Eval\\\\\\Trained_SBERT\\\\finetuned_indo_e5_v1\",\n",
    "    \"SimCSE IndoBERT\": r\"D:\\71210730\\Eval\\\\\\Trained_SBERT\\\\finetuned_simcse-indobert-base_v1\", \n",
    "    \"NusaBERT Base\": r\"D:\\71210730\\Eval\\\\\\Trained_SBERT\\\\finetuned_all-nusabert-base_v1\",\n",
    "    \"NusaBERT Large\": r\"D:\\71210730\\Eval\\\\\\Trained_SBERT\\\\finetuned_nusabert_large_v1\"\n",
    "}\n",
    "\n",
    "TEST_DATA_PATH = \"D:\\\\71210730\\\\Versi 4\\\\Training SBERT\\\\test_sbert.csv\"\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "df_test = pd.read_csv(TEST_DATA_PATH, encoding='utf-8-sig')\n",
    "sentences1 = df_test['text_1'].tolist()\n",
    "sentences2 = df_test['text_2'].tolist()\n",
    "gold_scores = df_test['score_norm'].tolist()\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Mulai Evaluasi Komprehensif...\")\n",
    "\n",
    "for model_name, model_path in TRAINED_MODELS.items():\n",
    "    print(f\"\\nðŸ”¹ Menguji: {model_name}...\")\n",
    "    try:\n",
    "        model = SentenceTransformer(model_path)\n",
    "        \n",
    "        prefix = \"query: \" if \"e5\" in model_name.lower() else \"\"\n",
    "        input_s1 = [prefix + str(s) for s in sentences1]\n",
    "        input_s2 = [prefix + str(s) for s in sentences2]\n",
    "        \n",
    "        emb1 = model.encode(input_s1, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "        emb2 = model.encode(input_s2, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "        \n",
    "        cosine_scores = util.cos_sim(emb1, emb2).diagonal().cpu().numpy()\n",
    "        \n",
    "        # Hitung Spearman\n",
    "        spearman_score, _ = spearmanr(gold_scores, cosine_scores)\n",
    "        \n",
    "        # Hitung Pearson (TAMBAHAN)\n",
    "        pearson_score, _ = pearsonr(gold_scores, cosine_scores)\n",
    "        \n",
    "        print(f\"   >> Spearman: {spearman_score:.4f}\")\n",
    "        print(f\"   >> Pearson : {pearson_score:.4f}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Spearman\": spearman_score,\n",
    "            \"Pearson\": pearson_score\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "\n",
    "# --- TABEL FINAL ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“Š TABEL PERBANDINGAN PERFORMA MODEL\")\n",
    "print(\"=\"*50)\n",
    "df_res = pd.DataFrame(results)\n",
    "# Urutkan berdasarkan Spearman (karena ini metrik utama skripsi kamu)\n",
    "df_res = df_res.sort_values(by=\"Spearman\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(df_res)\n",
    "df_res.to_csv(\"evaluasi_lengkap_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669d34b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Load model: nusabert-base ===\n",
      "Path: D:\\\\Media\\\\Kuliah\\\\Skripsi\\\\ScripTI\\\\Versi 4\\\\Model\\\\hf_models\\\\LazarusNLP__all-nusabert-base-v4\n",
      "\n",
      "=== Load model: sbert-nusabert-base ===\n",
      "Path: D:\\\\Media\\\\Kuliah\\\\Skripsi\\\\ScripTI\\\\Versi 4\\\\Model\\\\Trained_SBERT\\\\finetuned_all-nusabert-base_v1\n",
      "\n",
      "Hasil detail disimpan ke: hasil_perbandingan_model.csv\n",
      "\n",
      "================ RINGKASAN PER PASANGAN KALIMAT ================\n",
      "\n",
      "============================================================\n",
      "Pair A1 (in_domain_strong - Judul batik kawung, metode sama)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Pengenalan pola batik kawung menggunakan metode ellipse hough transform.\n",
      "Kalimat B : Pengenalan motif batik kawung dengan pendekatan ellipse hough transform.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :  92.7%\n",
      "Hasil Model B (      sbert-nusabert-base) :  98.1%\n",
      "\n",
      "Harusnya (ekspektasi) : Tinggi (mendekati 100%, karena topik & formulasi sangat mirip).\n",
      "\n",
      "============================================================\n",
      "Pair A2 (in_domain_strong - YOLOv5 deteksi ekspresi wajah)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Penelitian ini menggunakan YOLOv5 untuk mendeteksi ekspresi wajah secara real time.\n",
      "Kalimat B : YOLOv5 digunakan dalam penelitian ini untuk deteksi ekspresi wajah secara waktu nyata.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :  93.9%\n",
      "Hasil Model B (      sbert-nusabert-base) :  97.8%\n",
      "\n",
      "Harusnya (ekspektasi) : Tinggi (mendekati 100%, karena topik & formulasi sangat mirip).\n",
      "\n",
      "============================================================\n",
      "Pair A3 (in_domain_strong - Sistem informasi akademik)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Sistem informasi akademik ini dirancang untuk mengelola data mahasiswa, dosen, dan mata kuliah.\n",
      "Kalimat B : Aplikasi informasi akademik dibangun untuk pengelolaan data mahasiswa, staf pengajar, serta mata kuliah.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :  88.6%\n",
      "Hasil Model B (      sbert-nusabert-base) :  97.7%\n",
      "\n",
      "Harusnya (ekspektasi) : Tinggi (mendekati 100%, karena topik & formulasi sangat mirip).\n",
      "\n",
      "============================================================\n",
      "Pair B1 (in_domain_medium - Klasifikasi batik vs daun (CNN sama, objek beda))\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Penelitian ini berfokus pada klasifikasi gambar motif batik menggunakan CNN.\n",
      "Kalimat B : Penelitian ini berfokus pada klasifikasi citra daun menggunakan jaringan syaraf konvolusional.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :  49.9%\n",
      "Hasil Model B (      sbert-nusabert-base) :  66.4%\n",
      "\n",
      "Harusnya (ekspektasi) : Sedang (masih cukup tinggi, tapi tidak setinggi in-domain kuat).\n",
      "\n",
      "============================================================\n",
      "Pair B2 (in_domain_medium - Rekomendasi buku vs film)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Sistem ini memberikan rekomendasi buku berdasarkan riwayat peminjaman pengguna.\n",
      "Kalimat B : Aplikasi ini menyarankan film berdasarkan rating yang diberikan pengguna sebelumnya.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :  41.3%\n",
      "Hasil Model B (      sbert-nusabert-base) :  54.0%\n",
      "\n",
      "Harusnya (ekspektasi) : Sedang (masih cukup tinggi, tapi tidak setinggi in-domain kuat).\n",
      "\n",
      "============================================================\n",
      "Pair C1 (negation - Menggunakan vs TIDAK menggunakan YOLO)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Penelitian ini menggunakan YOLOv5 sebagai metode utama deteksi objek.\n",
      "Kalimat B : Penelitian ini tidak menggunakan YOLOv5 sebagai metode utama deteksi objek.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :  76.3%\n",
      "Hasil Model B (      sbert-nusabert-base) :  90.9%\n",
      "\n",
      "Harusnya (ekspektasi) : Rendah (kalimat berlawanan makna, seharusnya tidak dianggap mirip).\n",
      "\n",
      "============================================================\n",
      "Pair C2 (negation - Tujuan sistem vs TIDAK bertujuan)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Sistem ini bertujuan meningkatkan efisiensi proses pengolahan data transaksi.\n",
      "Kalimat B : Sistem ini tidak bertujuan meningkatkan efisiensi proses pengolahan data transaksi.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :  29.4%\n",
      "Hasil Model B (      sbert-nusabert-base) :  58.2%\n",
      "\n",
      "Harusnya (ekspektasi) : Rendah (kalimat berlawanan makna, seharusnya tidak dianggap mirip).\n",
      "\n",
      "============================================================\n",
      "Pair D1 (out_of_domain - Kalimat sehari-hari vs kalimat skripsi)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Hari ini saya pergi ke pasar untuk membeli sayur dan buah.\n",
      "Kalimat B : Penelitian ini mengembangkan sistem deteksi kemiripan proposal tugas akhir.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :   0.0%\n",
      "Hasil Model B (      sbert-nusabert-base) :   0.0%\n",
      "\n",
      "Harusnya (ekspektasi) : Sangat rendah (kalimat berbeda domain/topik).\n",
      "\n",
      "============================================================\n",
      "Pair D2 (out_of_domain - Hobi vs CNN)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Aku suka mendengarkan musik sambil bermain game di akhir pekan.\n",
      "Kalimat B : Model CNN dilatih menggunakan dataset citra berukuran 224 kali 224 piksel.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :   0.0%\n",
      "Hasil Model B (      sbert-nusabert-base) :   0.0%\n",
      "\n",
      "Harusnya (ekspektasi) : Sangat rendah (kalimat berbeda domain/topik).\n",
      "\n",
      "============================================================\n",
      "Pair E1 (identical - Kalimat sama persis)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Dataset yang terbatas menjadi tantangan tersendiri dalam membangun model ini.\n",
      "Kalimat B : Dataset yang terbatas menjadi tantangan tersendiri dalam membangun model ini.\n",
      "\n",
      "Hasil Model A (            nusabert-base) : 100.0%\n",
      "Hasil Model B (      sbert-nusabert-base) : 100.0%\n",
      "\n",
      "Harusnya (ekspektasi) : Sangat tinggi â‰ˆ 100% (kalimat identik).\n",
      "\n",
      "============================================================\n",
      "Pair E2 (paraphrase_close - Kalimat hampir sama, parafrase ringan)\n",
      "------------------------------------------------------------\n",
      "Kalimat A : Dataset yang terbatas menjadi tantangan tersendiri dalam membangun model ini.\n",
      "Kalimat B : Keterbatasan dataset menjadi tantangan utama dalam membangun model ini.\n",
      "\n",
      "Hasil Model A (            nusabert-base) :  93.8%\n",
      "Hasil Model B (      sbert-nusabert-base) :  96.6%\n",
      "\n",
      "Harusnya (ekspektasi) : Tinggi (80â€“100%, karena parafrase dekat).\n",
      "\n",
      "============================================================\n",
      "Selesai.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ======================= KONFIGURASI MODEL =======================\n",
    "MODEL_PATHS = {\n",
    "    \"nusabert-base\": r\"D:\\\\Media\\\\Kuliah\\\\Skripsi\\\\ScripTI\\\\Versi 4\\\\Model\\\\hf_models\\\\LazarusNLP__all-nusabert-base-v4\",\n",
    "    \"sbert-nusabert-base\": r\"D:\\\\Media\\\\Kuliah\\\\Skripsi\\\\ScripTI\\\\Versi 4\\\\Model\\\\Trained_SBERT\\\\finetuned_all-nusabert-base_v1\",\n",
    "}\n",
    "\n",
    "\n",
    "# ======================= PASANGAN KALIMAT UJI =======================\n",
    "TEST_PAIRS = [\n",
    "    # ---------- A: In-domain kuat ----------\n",
    "    {\n",
    "        \"id\": \"A1\",\n",
    "        \"group\": \"in_domain_strong\",\n",
    "        \"desc\": \"Judul batik kawung, metode sama\",\n",
    "        \"s1\": \"Pengenalan pola batik kawung menggunakan metode ellipse hough transform.\",\n",
    "        \"s2\": \"Pengenalan motif batik kawung dengan pendekatan ellipse hough transform.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"A2\",\n",
    "        \"group\": \"in_domain_strong\",\n",
    "        \"desc\": \"YOLOv5 deteksi ekspresi wajah\",\n",
    "        \"s1\": \"Penelitian ini menggunakan YOLOv5 untuk mendeteksi ekspresi wajah secara real time.\",\n",
    "        \"s2\": \"YOLOv5 digunakan dalam penelitian ini untuk deteksi ekspresi wajah secara waktu nyata.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"A3\",\n",
    "        \"group\": \"in_domain_strong\",\n",
    "        \"desc\": \"Sistem informasi akademik\",\n",
    "        \"s1\": \"Sistem informasi akademik ini dirancang untuk mengelola data mahasiswa, dosen, dan mata kuliah.\",\n",
    "        \"s2\": \"Aplikasi informasi akademik dibangun untuk pengelolaan data mahasiswa, staf pengajar, serta mata kuliah.\",\n",
    "    },\n",
    "\n",
    "    # ---------- B: In-domain sedang ----------\n",
    "    {\n",
    "        \"id\": \"B1\",\n",
    "        \"group\": \"in_domain_medium\",\n",
    "        \"desc\": \"Klasifikasi batik vs daun (CNN sama, objek beda)\",\n",
    "        \"s1\": \"Penelitian ini berfokus pada klasifikasi gambar motif batik menggunakan CNN.\",\n",
    "        \"s2\": \"Penelitian ini berfokus pada klasifikasi citra daun menggunakan jaringan syaraf konvolusional.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"B2\",\n",
    "        \"group\": \"in_domain_medium\",\n",
    "        \"desc\": \"Rekomendasi buku vs film\",\n",
    "        \"s1\": \"Sistem ini memberikan rekomendasi buku berdasarkan riwayat peminjaman pengguna.\",\n",
    "        \"s2\": \"Aplikasi ini menyarankan film berdasarkan rating yang diberikan pengguna sebelumnya.\",\n",
    "    },\n",
    "\n",
    "    # ---------- C: Negasi ----------\n",
    "    {\n",
    "        \"id\": \"C1\",\n",
    "        \"group\": \"negation\",\n",
    "        \"desc\": \"Menggunakan vs TIDAK menggunakan YOLO\",\n",
    "        \"s1\": \"Penelitian ini menggunakan YOLOv5 sebagai metode utama deteksi objek.\",\n",
    "        \"s2\": \"Penelitian ini tidak menggunakan YOLOv5 sebagai metode utama deteksi objek.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"C2\",\n",
    "        \"group\": \"negation\",\n",
    "        \"desc\": \"Tujuan sistem vs TIDAK bertujuan\",\n",
    "        \"s1\": \"Sistem ini bertujuan meningkatkan efisiensi proses pengolahan data transaksi.\",\n",
    "        \"s2\": \"Sistem ini tidak bertujuan meningkatkan efisiensi proses pengolahan data transaksi.\",\n",
    "    },\n",
    "\n",
    "    # ---------- D: Out-of-domain ----------\n",
    "    {\n",
    "        \"id\": \"D1\",\n",
    "        \"group\": \"out_of_domain\",\n",
    "        \"desc\": \"Kalimat sehari-hari vs kalimat skripsi\",\n",
    "        \"s1\": \"Hari ini saya pergi ke pasar untuk membeli sayur dan buah.\",\n",
    "        \"s2\": \"Penelitian ini mengembangkan sistem deteksi kemiripan proposal tugas akhir.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"D2\",\n",
    "        \"group\": \"out_of_domain\",\n",
    "        \"desc\": \"Hobi vs CNN\",\n",
    "        \"s1\": \"Aku suka mendengarkan musik sambil bermain game di akhir pekan.\",\n",
    "        \"s2\": \"Model CNN dilatih menggunakan dataset citra berukuran 224 kali 224 piksel.\",\n",
    "    },\n",
    "\n",
    "    # ---------- E: Kalimat sama / hampir sama ----------\n",
    "    {\n",
    "        \"id\": \"E1\",\n",
    "        \"group\": \"identical\",\n",
    "        \"desc\": \"Kalimat sama persis\",\n",
    "        \"s1\": \"Dataset yang terbatas menjadi tantangan tersendiri dalam membangun model ini.\",\n",
    "        \"s2\": \"Dataset yang terbatas menjadi tantangan tersendiri dalam membangun model ini.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"E2\",\n",
    "        \"group\": \"paraphrase_close\",\n",
    "        \"desc\": \"Kalimat hampir sama, parafrase ringan\",\n",
    "        \"s1\": \"Dataset yang terbatas menjadi tantangan tersendiri dalam membangun model ini.\",\n",
    "        \"s2\": \"Keterbatasan dataset menjadi tantangan utama dalam membangun model ini.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# ======================= FUNGSI BANTU =======================\n",
    "\n",
    "def evaluate_model(model_name: str, model: SentenceTransformer):\n",
    "    rows = []\n",
    "    for pair in TEST_PAIRS:\n",
    "        s1 = pair[\"s1\"]\n",
    "        s2 = pair[\"s2\"]\n",
    "\n",
    "        emb1 = model.encode(s1, convert_to_tensor=True, normalize_embeddings=True)\n",
    "        emb2 = model.encode(s2, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "        sim = util.cos_sim(emb1, emb2).item()  # -1..1\n",
    "        sim_clamped = max(0.0, min(1.0, sim))\n",
    "        sim_percent = round(sim_clamped * 100, 1)\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": model_name,\n",
    "            \"pair_id\": pair[\"id\"],\n",
    "            \"group\": pair[\"group\"],\n",
    "            \"desc\": pair[\"desc\"],\n",
    "            \"s1\": s1,\n",
    "            \"s2\": s2,\n",
    "            \"similarity_raw\": sim,\n",
    "            \"similarity_percent\": sim_percent,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "\n",
    "def expected_text_for_group(group: str) -> str:\n",
    "    if group == \"in_domain_strong\":\n",
    "        return \"Tinggi (mendekati 100%, karena topik & formulasi sangat mirip).\"\n",
    "    if group == \"in_domain_medium\":\n",
    "        return \"Sedang (masih cukup tinggi, tapi tidak setinggi in-domain kuat).\"\n",
    "    if group == \"negation\":\n",
    "        return \"Rendah (kalimat berlawanan makna, seharusnya tidak dianggap mirip).\"\n",
    "    if group == \"out_of_domain\":\n",
    "        return \"Sangat rendah (kalimat berbeda domain/topik).\"\n",
    "    if group == \"identical\":\n",
    "        return \"Sangat tinggi â‰ˆ 100% (kalimat identik).\"\n",
    "    if group == \"paraphrase_close\":\n",
    "        return \"Tinggi (80â€“100%, karena parafrase dekat).\"\n",
    "    return \"-\"\n",
    "\n",
    "\n",
    "# ======================= MAIN =======================\n",
    "\n",
    "def main():\n",
    "    if not MODEL_PATHS:\n",
    "        print(\"Harap isi dulu MODEL_PATHS dengan path model yang ingin dibandingkan.\")\n",
    "        return\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for name, path in MODEL_PATHS.items():\n",
    "        print(f\"\\n=== Load model: {name} ===\")\n",
    "        print(f\"Path: {path}\")\n",
    "        model = SentenceTransformer(path)\n",
    "        rows = evaluate_model(name, model)\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "\n",
    "    # Simpan ke CSV tetap ada\n",
    "    out_path = \"hasil_perbandingan_model.csv\"\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nHasil detail disimpan ke: {out_path}\")\n",
    "\n",
    "    # ================= CETAK VERSI 'NARATIF' PER PASANGAN =================\n",
    "    print(\"\\n================ RINGKASAN PER PASANGAN KALIMAT ================\\n\")\n",
    "\n",
    "    # Urutan model untuk label \"Model A/B/C\"\n",
    "    model_names = list(MODEL_PATHS.keys())\n",
    "    label_for_model = {name: f\"Model {chr(ord('A') + i)}\" for i, name in enumerate(model_names)}\n",
    "\n",
    "    for pair in TEST_PAIRS:\n",
    "        pid = pair[\"id\"]\n",
    "        group = pair[\"group\"]\n",
    "        desc = pair[\"desc\"]\n",
    "\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Pair {pid} ({group} - {desc})\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Kalimat A : {pair['s1']}\")\n",
    "        print(f\"Kalimat B : {pair['s2']}\\n\")\n",
    "\n",
    "        # hasil tiap model\n",
    "        for name in model_names:\n",
    "            label = label_for_model[name]\n",
    "            row = df[(df[\"pair_id\"] == pid) & (df[\"model\"] == name)]\n",
    "            if row.empty:\n",
    "                continue\n",
    "            percent = row.iloc[0][\"similarity_percent\"]\n",
    "            print(f\"Hasil {label} ({name:>25}) : {percent:5.1f}%\")\n",
    "\n",
    "        print(f\"\\nHarusnya (ekspektasi) : {expected_text_for_group(group)}\\n\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Selesai.\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
