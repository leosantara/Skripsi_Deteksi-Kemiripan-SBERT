{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2e7e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "[LOAD MODEL]\n",
      "\n",
      "=== Pair 1 ===\n",
      "Kalimat A : Sistem ini bertujuan untuk mendeteksi kemiripan proposal tugas akhir berbasis Sentence-BERT.\n",
      "Kalimat B : Penelitian ini mengembangkan sistem pendeteksi kemiripan proposal skripsi menggunakan model SBERT.\n",
      "Hasil BASE (sebelum FT) : 81.80%\n",
      "Hasil FT   (sesudah FT) : 86.25%\n",
      "\n",
      "=== Pair 2 ===\n",
      "Kalimat A : Dataset proposal diambil dari platform ScripTI yang berisi ribuan judul tugas akhir.\n",
      "Kalimat B : Data penelitian dikumpulkan dari jurnal ilmiah nasional dan internasional.\n",
      "Hasil BASE (sebelum FT) : 45.35%\n",
      "Hasil FT   (sesudah FT) : 55.73%\n",
      "\n",
      "=== Pair 3 ===\n",
      "Kalimat A : Sistem rekomendasi film menggunakan pendekatan collaborative filtering berbasis rating pengguna.\n",
      "Kalimat B : Harga saham perusahaan teknologi mengalami kenaikan tajam akibat sentimen pasar global.\n",
      "Hasil BASE (sebelum FT) : 11.01%\n",
      "Hasil FT   (sesudah FT) : 13.09%\n",
      "\n",
      "=== Pair 4 ===\n",
      "Kalimat A : Metode yang digunakan adalah fine-tuning Sentence-BERT dengan objective Semantic Textual Similarity.\n",
      "Kalimat B : Metode yang digunakan adalah fine-tuning Sentence-BERT dengan objective Semantic Textual Similarity.\n",
      "Hasil BASE (sebelum FT) : 100.00%\n",
      "Hasil FT   (sesudah FT) : 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# ==== 1. Path model (sesuaikan kalau beda) ====\n",
    "BASE_MODEL_PATH = \"D:\\\\Media\\\\Kuliah\\\\Skripsi\\\\ScripTI\\\\Versi 4\\\\Model\\\\hf_models\\\\LazarusNLP__all-nusabert-large-v4\"\n",
    "FT_MODEL_PATH   = \"D:\\\\Media\\\\Kuliah\\\\Skripsi\\\\ScripTI\\\\Versi 4\\\\Model\\\\Trained_SBERT\\\\finetuned_nusabert_large_v1\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "print(\"\\n[LOAD MODEL]\")\n",
    "base_model = SentenceTransformer(BASE_MODEL_PATH, device=device)\n",
    "ft_model   = SentenceTransformer(FT_MODEL_PATH, device=device)\n",
    "\n",
    "# ==== 2. Beberapa pasangan kalimat uji ====\n",
    "pairs = [\n",
    "    # Dalam domain, sangat mirip\n",
    "    (\n",
    "        \"Sistem ini bertujuan untuk mendeteksi kemiripan proposal tugas akhir berbasis Sentence-BERT.\",\n",
    "        \"Penelitian ini mengembangkan sistem pendeteksi kemiripan proposal skripsi menggunakan model SBERT.\"\n",
    "    ),\n",
    "    # Dalam domain, beda topik (mirip sedang)\n",
    "    (\n",
    "        \"Dataset proposal diambil dari platform ScripTI yang berisi ribuan judul tugas akhir.\",\n",
    "        \"Data penelitian dikumpulkan dari jurnal ilmiah nasional dan internasional.\"\n",
    "    ),\n",
    "    # Di luar domain, harusnya rendah\n",
    "    (\n",
    "        \"Sistem rekomendasi film menggunakan pendekatan collaborative filtering berbasis rating pengguna.\",\n",
    "        \"Harga saham perusahaan teknologi mengalami kenaikan tajam akibat sentimen pasar global.\"\n",
    "    ),\n",
    "    # Identik (kontrol)\n",
    "    (\n",
    "        \"Metode yang digunakan adalah fine-tuning Sentence-BERT dengan objective Semantic Textual Similarity.\",\n",
    "        \"Metode yang digunakan adalah fine-tuning Sentence-BERT dengan objective Semantic Textual Similarity.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ==== 3. Hitung & tampilkan skor ====\n",
    "for i, (s1, s2) in enumerate(pairs, start=1):\n",
    "    emb1_base = base_model.encode(s1, convert_to_tensor=True)\n",
    "    emb2_base = base_model.encode(s2, convert_to_tensor=True)\n",
    "    emb1_ft   = ft_model.encode(s1, convert_to_tensor=True)\n",
    "    emb2_ft   = ft_model.encode(s2, convert_to_tensor=True)\n",
    "\n",
    "    sim_base = util.cos_sim(emb1_base, emb2_base).item()\n",
    "    sim_ft   = util.cos_sim(emb1_ft, emb2_ft).item()\n",
    "\n",
    "    print(f\"\\n=== Pair {i} ===\")\n",
    "    print(\"Kalimat A :\", s1)\n",
    "    print(\"Kalimat B :\", s2)\n",
    "    print(f\"Hasil BASE (sebelum FT) : {sim_base*100:.2f}%\")\n",
    "    print(f\"Hasil FT   (sesudah FT) : {sim_ft*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c39a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SISTEM OPERASI: Windows 10\n",
      "PYTHON VERSION: 3.11.9\n",
      "==================================================\n",
      "LIBRARY / FRAMEWORK       | VERSI SAAT INI      \n",
      "--------------------------------------------------\n",
      "PyTorch                   | 2.6.0+cu124\n",
      "Sentence-Transformers     | 3.4.1\n",
      "FAISS                     | 1.13.0\n",
      "Pandas                    | 2.3.3\n",
      "NumPy                     | 2.2.6\n",
      "FastAPI                   | 0.121.2\n",
      "Uvicorn                   | 0.38.0\n",
      "Google GenAI SDK          | 0.8.5\n",
      "==================================================\n",
      "\n",
      "[GPU STATUS CHECK]\n",
      "✅ CUDA Aktif: Ya\n",
      "✅ GPU Terdeteksi: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "✅ VRAM Total: 4.29 GB\n",
      "✅ CUDA Version: 12.4\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ================= SYSTEM DIAGNOSTIC TOOL =================\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "def check_version(package_name, alias=None):\n",
    "    try:\n",
    "        if alias:\n",
    "            module = __import__(alias)\n",
    "        else:\n",
    "            module = __import__(package_name)\n",
    "        \n",
    "        version = getattr(module, '__version__', 'Terinstall (Versi tidak diketahui)')\n",
    "        return version\n",
    "    except ImportError:\n",
    "        return \"TIDAK TERINSTALL ❌\"\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"SISTEM OPERASI: {platform.system()} {platform.release()}\")\n",
    "print(f\"PYTHON VERSION: {sys.version.split()[0]}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'LIBRARY / FRAMEWORK':<25} | {'VERSI SAAT INI':<20}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 1. CORE AI ---\n",
    "print(f\"{'PyTorch':<25} | {check_version('torch')}\")\n",
    "print(f\"{'Sentence-Transformers':<25} | {check_version('sentence_transformers')}\")\n",
    "print(f\"{'FAISS':<25} | {check_version('faiss')}\")\n",
    "\n",
    "# --- 2. DATA PROCESSING ---\n",
    "print(f\"{'Pandas':<25} | {check_version('pandas')}\")\n",
    "print(f\"{'NumPy':<25} | {check_version('numpy')}\")\n",
    "\n",
    "# --- 3. BACKEND API ---\n",
    "print(f\"{'FastAPI':<25} | {check_version('fastapi')}\")\n",
    "print(f\"{'Uvicorn':<25} | {check_version('uvicorn')}\")\n",
    "\n",
    "# --- 4. LLM API ---\n",
    "# Google Generative AI import-nya agak beda\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    ver = genai.__version__\n",
    "except:\n",
    "    ver = \"TIDAK TERINSTALL ❌\"\n",
    "print(f\"{'Google GenAI SDK':<25} | {ver}\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- KHUSUS CEK GPU (WAJIB UTK RTX 3060) ---\n",
    "import torch\n",
    "print(\"\\n[GPU STATUS CHECK]\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ CUDA Aktif: Ya\")\n",
    "    print(f\"✅ GPU Terdeteksi: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"✅ VRAM Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"✅ CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"❌ CUDA Tidak Aktif (Training akan lambat pakai CPU!)\")\n",
    "    print(\"   Saran: Install PyTorch versi CUDA di https://pytorch.org/\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ebb7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SISTEM OPERASI: Windows 10\n",
      "PYTHON VERSION: 3.11.9\n",
      "==================================================\n",
      "LIBRARY / FRAMEWORK       | VERSI SAAT INI      \n",
      "--------------------------------------------------\n",
      "PyTorch                   | 2.6.0+cu124\n",
      "HuggingFace Transformers  | 4.57.1\n",
      "HuggingFace Accelerate    | 1.11.0\n",
      "Sentence-Transformers     | 3.4.1\n",
      "FAISS                     | 1.13.0\n",
      "Scikit-Learn              | 1.7.2\n",
      "Pandas                    | 2.3.3\n",
      "NumPy                     | 2.2.6\n",
      "Tqdm (Progress Bar)       | 4.67.1\n",
      "FastAPI                   | 0.121.2\n",
      "Uvicorn (Server)          | 0.38.0\n",
      "Python-Multipart          | ❌ TIDAK TERINSTALL\n",
      "Google GenAI SDK          | 0.8.5\n",
      "==================================================\n",
      "Regex (re)                | Built-in Python Lib (Std)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ================= SYSTEM DIAGNOSTIC TOOL (LENGKAP) =================\n",
    "import sys\n",
    "import platform\n",
    "import importlib\n",
    "\n",
    "def check_library(package_name, display_name=None):\n",
    "    if display_name is None:\n",
    "        display_name = package_name\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(package_name)\n",
    "        # Coba berbagai cara standar mengambil versi\n",
    "        version = getattr(module, '__version__', None)\n",
    "        if not version:\n",
    "            # Kadang versi ada di sub-atribut\n",
    "            version = getattr(module, 'version', 'Terinstall (Versi n/a)')\n",
    "        return f\"{display_name:<25} | {version}\"\n",
    "    except ImportError:\n",
    "        return f\"{display_name:<25} | ❌ TIDAK TERINSTALL\"\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"SISTEM OPERASI: {platform.system()} {platform.release()}\")\n",
    "print(f\"PYTHON VERSION: {sys.version.split()[0]}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'LIBRARY / FRAMEWORK':<25} | {'VERSI SAAT INI':<20}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 1. CORE DEEP LEARNING ---\n",
    "print(check_library('torch', 'PyTorch'))\n",
    "print(check_library('transformers', 'HuggingFace Transformers'))\n",
    "print(check_library('accelerate', 'HuggingFace Accelerate')) # PENTING UTK GPU\n",
    "print(check_library('sentence_transformers', 'Sentence-Transformers'))\n",
    "\n",
    "# --- 2. VECTOR SEARCH & CLUSTERING ---\n",
    "print(check_library('faiss', 'FAISS'))  # Atau faiss-gpu / faiss-cpu\n",
    "print(check_library('sklearn', 'Scikit-Learn')) # PENTING UTK CLUSTERING & SPLIT\n",
    "\n",
    "# --- 3. DATA PROCESSING ---\n",
    "print(check_library('pandas', 'Pandas'))\n",
    "print(check_library('numpy', 'NumPy'))\n",
    "print(check_library('tqdm', 'Tqdm (Progress Bar)'))\n",
    "\n",
    "# --- 4. BACKEND API ---\n",
    "print(check_library('fastapi', 'FastAPI'))\n",
    "print(check_library('uvicorn', 'Uvicorn (Server)'))\n",
    "print(check_library('python_multipart', 'Python-Multipart')) # Utk Upload File\n",
    "\n",
    "# --- 5. LLM API ---\n",
    "print(check_library('google.generativeai', 'Google GenAI SDK'))\n",
    "\n",
    "print(\"=\"*50)\n",
    "# Catatan soal Regex\n",
    "import re\n",
    "print(f\"{'Regex (re)':<25} | Built-in Python Lib (Std)\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a90289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedang menganalisis model...\n",
      "✅ LazarusNLP__simcse-indobert-base - OK\n",
      "✅ LazarusNLP__all-nusabert-base-v4 - OK\n",
      "✅ LazarusNLP__all-nusabert-large-v4 - OK\n",
      "✅ LazarusNLP__all-indo-e5-small-v4 - OK\n",
      "\n",
      "=== TABEL SPESIFIKASI MODEL ===\n",
      "                       Nama Model Arsitektur  Dimensi (Hidden Size)  Jumlah Layer  Attention Heads Vocab Size  Max Position               Tokenizer     Pooling Strategy      Instruction-Tuned\n",
      " LazarusNLP__simcse-indobert-base       BERT                    768            12               12     50,000           512       BertTokenizerFast Default (Cek Manual)                  Tidak\n",
      " LazarusNLP__all-nusabert-base-v4       BERT                    768            12               12     32,032           512       BertTokenizerFast Default (Cek Manual)                  Tidak\n",
      "LazarusNLP__all-nusabert-large-v4       BERT                   1024            24               16     32,032           512       BertTokenizerFast Default (Cek Manual)                  Tidak\n",
      " LazarusNLP__all-indo-e5-small-v4       BERT                    384            12               12    250,037           512 XLMRobertaTokenizerFast         Mean Pooling Ya (query: / passage:)\n",
      "\n",
      "File tersimpan: tabel_spesifikasi_model.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "# Masukkan path folder lokal model kamu (atau nama Hugging Face jika online)\n",
    "MODEL_PATHS = [\n",
    "    r\"D:\\Media\\Kuliah\\Skripsi\\ScripTI\\Versi 4\\Model\\hf_models\\LazarusNLP__simcse-indobert-base\",\n",
    "    r\"D:\\Media\\Kuliah\\Skripsi\\ScripTI\\Versi 4\\Model\\hf_models\\LazarusNLP__all-nusabert-base-v4\",\n",
    "    r\"D:\\Media\\Kuliah\\Skripsi\\ScripTI\\Versi 4\\Model\\hf_models\\LazarusNLP__all-nusabert-large-v4\",\n",
    "    r\"D:\\Media\\Kuliah\\Skripsi\\ScripTI\\Versi 4\\Model\\hf_models\\LazarusNLP__all-indo-e5-small-v4\"\n",
    "]\n",
    "\n",
    "def get_pooling_mode(model_path):\n",
    "    \"\"\"Mencoba mendeteksi mode pooling dari file konfigurasi SBERT\"\"\"\n",
    "    try:\n",
    "        # Cek file config pooling standar SBERT\n",
    "        pool_config_path = os.path.join(model_path, \"1_Pooling\", \"config.json\")\n",
    "        \n",
    "        if os.path.exists(pool_config_path):\n",
    "            with open(pool_config_path, 'r') as f:\n",
    "                conf = json.load(f)\n",
    "                if conf.get(\"pooling_mode_mean_tokens\"): return \"Mean Pooling\"\n",
    "                if conf.get(\"pooling_mode_cls_token\"): return \"CLS Pooling\"\n",
    "                if conf.get(\"pooling_mode_max_tokens\"): return \"Max Pooling\"\n",
    "        \n",
    "        # Fallback: Cek modules.json\n",
    "        modules_path = os.path.join(model_path, \"modules.json\")\n",
    "        if os.path.exists(modules_path):\n",
    "            with open(modules_path, 'r') as f:\n",
    "                mods = json.load(f)\n",
    "                # Biasanya modul pooling ada di urutan ke-1\n",
    "                for m in mods:\n",
    "                    if m['type'] == 'sentence_transformers.models.Pooling':\n",
    "                        # Kita harus buka file config di folder path-nya\n",
    "                        p_path = os.path.join(model_path, m['path'], \"config.json\")\n",
    "                        if os.path.exists(p_path):\n",
    "                            with open(p_path, 'r') as pf:\n",
    "                                pconf = json.load(pf)\n",
    "                                if pconf.get(\"pooling_mode_mean_tokens\"): return \"Mean Pooling\"\n",
    "                                if pconf.get(\"pooling_mode_cls_token\"): return \"CLS Pooling\"\n",
    "    except:\n",
    "        pass\n",
    "    return \"Default (Cek Manual)\"\n",
    "\n",
    "def check_instruction_tuned(model_path):\n",
    "    \"\"\"Mendeteksi apakah model butuh prompt (Instruction-Tuned)\"\"\"\n",
    "    # Cek nama folder/model\n",
    "    name = str(model_path).lower()\n",
    "    if \"e5\" in name or \"instruction\" in name:\n",
    "        return \"Ya (query: / passage:)\"\n",
    "    return \"Tidak\"\n",
    "\n",
    "# --- EKSEKUSI ---\n",
    "data = []\n",
    "\n",
    "print(\"Sedang menganalisis model...\")\n",
    "\n",
    "for path in MODEL_PATHS:\n",
    "    try:\n",
    "        # Load Config HuggingFace\n",
    "        config = AutoConfig.from_pretrained(path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "        \n",
    "        # Ambil nama folder terakhir sebagai nama model\n",
    "        model_name = os.path.basename(path)\n",
    "        if not model_name: model_name = path  # Fallback\n",
    "        \n",
    "        # Deteksi Arsitektur Dasar\n",
    "        arch = config.model_type.upper() # BERT, ROBERTA, etc\n",
    "        \n",
    "        # Deteksi Tokenizer\n",
    "        tok_type = type(tokenizer).__name__\n",
    "        \n",
    "        # Deteksi Pooling\n",
    "        pooling = get_pooling_mode(path)\n",
    "        \n",
    "        # Deteksi Instruction\n",
    "        instruction = check_instruction_tuned(path)\n",
    "        \n",
    "        # Masukkan ke data\n",
    "        data.append({\n",
    "            \"Nama Model\": model_name,\n",
    "            \"Arsitektur\": arch,\n",
    "            \"Dimensi (Hidden Size)\": config.hidden_size,\n",
    "            \"Jumlah Layer\": config.num_hidden_layers,\n",
    "            \"Attention Heads\": config.num_attention_heads,\n",
    "            \"Vocab Size\": f\"{config.vocab_size:,}\", # Format ribuan\n",
    "            \"Max Position\": config.max_position_embeddings,\n",
    "            \"Tokenizer\": tok_type,\n",
    "            \"Pooling Strategy\": pooling,\n",
    "            \"Instruction-Tuned\": instruction\n",
    "        })\n",
    "        print(f\"✅ {model_name} - OK\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal memproses {path}: {e}\")\n",
    "\n",
    "# Buat DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Tampilkan\n",
    "print(\"\\n=== TABEL SPESIFIKASI MODEL ===\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Simpan ke CSV biar gampang dicopy ke Word/Excel\n",
    "df.to_csv(\"tabel_spesifikasi_model.csv\", index=False)\n",
    "print(\"\\nFile tersimpan: tabel_spesifikasi_model.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
